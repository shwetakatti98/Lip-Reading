{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        out_x = x.transpose(1, 2)\n",
    "        out_x = out_x.contiguous()\n",
    "        dims = out_x.size()\n",
    "        out_x = out_x.view(dims[0], dims[1], dims[2]*dims[3]*dims[4])\n",
    "        return out_x\n",
    "\n",
    "class LipNet(nn.Module):\n",
    "    def __init__(self, hidden_size=256, vocab_size=28, n_layers=1, in_channels=1):\n",
    "        super(LipNet, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.in_channels = in_channels\n",
    "        self.conv1 = nn.Conv3d(in_channels=self.in_channels, out_channels=32, kernel_size=(3, 5, 5), \n",
    "                               stride=(1, 2, 2), padding=(1, 2, 2))\n",
    "        self.pooling = nn.MaxPool3d((1, 2, 2))\n",
    "        self.batchnorm1 = nn.BatchNorm3d(32)\n",
    "        self.conv2 = nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3, 5, 5), \n",
    "                               stride=(1, 2, 2), padding=(1, 2, 2))\n",
    "        self.batchnorm2 = nn.BatchNorm3d(64)\n",
    "        self.conv3 = nn.Conv3d(in_channels=64, out_channels=96, kernel_size=(3, 3, 3), \n",
    "                               stride=(1, 2, 2), padding=(1, 1, 1))\n",
    "        self.batchnorm3 = nn.BatchNorm3d(96)\n",
    "        self.flat = Flatten()\n",
    "        self.gru1 = nn.GRU(input_size=96, hidden_size=hidden_size, num_layers=self.n_layers, \n",
    "                           bidirectional=True, batch_first=True)\n",
    "        self.dense1 = nn.Linear(512, 28)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.conv1(input)\n",
    "        output = self.pooling(output)\n",
    "        output = self.conv2(output)\n",
    "        output = self.pooling(output)\n",
    "        output = self.conv3(output)\n",
    "\n",
    "        output = self.pooling(output)\n",
    "        output = self.flat(output)\n",
    "        output, hidden = self.gru1(output, hidden)\n",
    "        output = self.dense1(output)\n",
    "        #print(output.size())\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(2, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = LipNet()\n",
    "hidden = ln.init_hidden(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor(1, 1, 75, 50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = a.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.view(1, 3, 75*5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fuck = Variable(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       " (0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   3.3759  3.6246  3.4595  ...   3.5942  3.5296  3.5146\n",
       "   3.3747  3.6099  3.4315  ...   3.6024  3.5313  3.5329\n",
       "   3.3762  3.6023  3.4185  ...   3.6078  3.5310  3.5441\n",
       "            ...             â‹±             ...          \n",
       "   3.3956  3.5546  3.3931  ...   3.6289  3.5439  3.5675\n",
       "   3.4094  3.5355  3.3869  ...   3.6390  3.5493  3.5664\n",
       "   3.4403  3.4998  3.3749  ...   3.6572  3.5567  3.5620\n",
       " [torch.FloatTensor of size 1x75x28], Variable containing:\n",
       " ( 0 ,.,.) = \n",
       " \n",
       " Columns 0 to 8 \n",
       "    0.0116  0.0214 -0.0078  0.0019 -0.0451  0.0476  0.0336 -0.0120  0.0069\n",
       " \n",
       " Columns 9 to 17 \n",
       "    0.0408  0.0355  0.0540  0.0368  0.0726 -0.0092 -0.0157  0.0362  0.0592\n",
       " \n",
       " Columns 18 to 26 \n",
       "    0.0019 -0.0474 -0.0481 -0.0154 -0.0135  0.0476 -0.0887 -0.0228  0.0597\n",
       " \n",
       " Columns 27 to 35 \n",
       "   -0.0627  0.0537  0.0001 -0.0054  0.0166  0.0733 -0.0076 -0.0079  0.0295\n",
       " \n",
       " Columns 36 to 44 \n",
       "    0.0469  0.0128 -0.0708 -0.0088  0.0632 -0.0205  0.0250  0.0269 -0.0182\n",
       " \n",
       " Columns 45 to 53 \n",
       "   -0.0077  0.0261  0.0096  0.0593  0.0775  0.0789 -0.0529  0.0145 -0.0127\n",
       " \n",
       " Columns 54 to 62 \n",
       "   -0.0268 -0.0796 -0.0110  0.0571 -0.0179 -0.0417 -0.0482  0.0575 -0.0095\n",
       " \n",
       " Columns 63 to 71 \n",
       "   -0.0240 -0.0091 -0.0602 -0.0085  0.0705  0.0026  0.0218 -0.0492  0.0217\n",
       " \n",
       " Columns 72 to 80 \n",
       "   -0.0375 -0.0601  0.0411 -0.0623 -0.0558  0.0465 -0.0528 -0.0420 -0.0368\n",
       " \n",
       " Columns 81 to 89 \n",
       "    0.0095 -0.0733 -0.0235 -0.0876 -0.0472  0.1101  0.0041 -0.0054 -0.0433\n",
       " \n",
       " Columns 90 to 98 \n",
       "   -0.0612 -0.0537  0.0620 -0.0217 -0.0036  0.0173 -0.0029 -0.0101  0.0715\n",
       " \n",
       " Columns 99 to 107 \n",
       "    0.0134  0.0027  0.0139 -0.0375  0.0603  0.0640 -0.0133  0.0366  0.0103\n",
       " \n",
       " Columns 108 to 116 \n",
       "    0.0302  0.0071 -0.0274  0.0827 -0.0711 -0.0146  0.0289 -0.0055  0.0253\n",
       " \n",
       " Columns 117 to 125 \n",
       "    0.0383  0.0083  0.0155 -0.0596  0.0375 -0.0489  0.0248 -0.0084 -0.0019\n",
       " \n",
       " Columns 126 to 134 \n",
       "   -0.0466  0.0409 -0.0269  0.0108  0.0329  0.0064 -0.0755  0.0363 -0.0114\n",
       " \n",
       " Columns 135 to 143 \n",
       "   -0.0385  0.0038  0.0308 -0.0365  0.0110  0.0175 -0.0044 -0.0233  0.0438\n",
       " \n",
       " Columns 144 to 152 \n",
       "    0.0798  0.0107  0.0001 -0.0491 -0.0348  0.0362 -0.0432 -0.0717  0.0299\n",
       " \n",
       " Columns 153 to 161 \n",
       "   -0.0056  0.0107  0.0312 -0.0048 -0.0182  0.0724  0.0203 -0.0671  0.0367\n",
       " \n",
       " Columns 162 to 170 \n",
       "   -0.0511 -0.0040 -0.0043  0.0553 -0.0579  0.0115 -0.0451  0.0269  0.0827\n",
       " \n",
       " Columns 171 to 179 \n",
       "   -0.0009 -0.0503 -0.0073  0.0197 -0.0184 -0.0371  0.0352  0.0011  0.0045\n",
       " \n",
       " Columns 180 to 188 \n",
       "   -0.0052  0.0714  0.0030 -0.0769  0.0086 -0.0276  0.0676  0.0465 -0.0158\n",
       " \n",
       " Columns 189 to 197 \n",
       "   -0.0363  0.0592 -0.0248 -0.0093  0.0315 -0.0456  0.0370 -0.0160  0.0281\n",
       " \n",
       " Columns 198 to 206 \n",
       "    0.0671 -0.0091  0.0453 -0.0499 -0.0925  0.0230  0.0081  0.0169 -0.0245\n",
       " \n",
       " Columns 207 to 215 \n",
       "   -0.0639 -0.0224 -0.0123 -0.0526 -0.0180 -0.0261  0.0058 -0.0051  0.0404\n",
       " \n",
       " Columns 216 to 224 \n",
       "   -0.0025 -0.0018  0.0441 -0.0267  0.0332 -0.0149 -0.0638 -0.0444 -0.0291\n",
       " \n",
       " Columns 225 to 233 \n",
       "   -0.0308  0.0813  0.0015 -0.0776 -0.0470  0.0046  0.0419 -0.0231  0.0149\n",
       " \n",
       " Columns 234 to 242 \n",
       "    0.0554  0.0067  0.0132  0.0543 -0.0187 -0.0214  0.0252 -0.0112 -0.0019\n",
       " \n",
       " Columns 243 to 251 \n",
       "    0.0277 -0.0665 -0.1010  0.0151 -0.0514  0.0382  0.0074  0.0627  0.0202\n",
       " \n",
       " Columns 252 to 255 \n",
       "   -0.0033 -0.0395 -0.0061  0.0401\n",
       " \n",
       " ( 1 ,.,.) = \n",
       " \n",
       " Columns 0 to 8 \n",
       "   -0.0229  0.0823 -0.0212 -0.0028 -0.0114  0.0378 -0.0166 -0.1042  0.0362\n",
       " \n",
       " Columns 9 to 17 \n",
       "   -0.0445  0.0165 -0.0427  0.0438 -0.0241 -0.0149  0.0159 -0.0189  0.0257\n",
       " \n",
       " Columns 18 to 26 \n",
       "    0.0537 -0.0620 -0.0045  0.0570 -0.0763  0.0557  0.1183  0.0336  0.0621\n",
       " \n",
       " Columns 27 to 35 \n",
       "   -0.0077  0.0620  0.1131  0.0393 -0.0760 -0.0574  0.0052 -0.0335  0.0034\n",
       " \n",
       " Columns 36 to 44 \n",
       "   -0.0192 -0.0497  0.0366 -0.0224  0.0951  0.0545 -0.0027  0.0064  0.0147\n",
       " \n",
       " Columns 45 to 53 \n",
       "    0.0317 -0.0229 -0.0409  0.0411 -0.0025 -0.0262  0.0370  0.0356  0.0255\n",
       " \n",
       " Columns 54 to 62 \n",
       "    0.0332 -0.0346  0.1008  0.0420  0.0128 -0.0596 -0.0131 -0.0712  0.0377\n",
       " \n",
       " Columns 63 to 71 \n",
       "   -0.0035 -0.0672  0.0095 -0.0087  0.0752  0.0099  0.0454 -0.0225  0.0557\n",
       " \n",
       " Columns 72 to 80 \n",
       "   -0.0535 -0.0550  0.0092 -0.0818 -0.0879  0.0523 -0.0555 -0.0761 -0.0133\n",
       " \n",
       " Columns 81 to 89 \n",
       "    0.0298 -0.0173 -0.0491 -0.0773  0.0153  0.0048  0.0238 -0.0085  0.0503\n",
       " \n",
       " Columns 90 to 98 \n",
       "   -0.0482  0.0193  0.0534 -0.0274  0.0276  0.0255  0.0874  0.0407 -0.0247\n",
       " \n",
       " Columns 99 to 107 \n",
       "   -0.0413 -0.0339  0.0735 -0.0327 -0.0605  0.0198  0.0429  0.0305 -0.0561\n",
       " \n",
       " Columns 108 to 116 \n",
       "   -0.0503  0.0278 -0.0089 -0.0626  0.0052  0.0510  0.0075  0.0175 -0.0901\n",
       " \n",
       " Columns 117 to 125 \n",
       "   -0.0424 -0.0185  0.0271  0.0375 -0.0529 -0.0002 -0.0412 -0.0411 -0.0135\n",
       " \n",
       " Columns 126 to 134 \n",
       "   -0.0142 -0.0041  0.0381  0.0386  0.0385 -0.0495  0.0025  0.0249 -0.0127\n",
       " \n",
       " Columns 135 to 143 \n",
       "    0.0378 -0.0174 -0.0183 -0.0199 -0.0553 -0.0099 -0.0191 -0.0561 -0.0413\n",
       " \n",
       " Columns 144 to 152 \n",
       "   -0.0085 -0.0339 -0.0166  0.0272  0.0771  0.0361  0.0332 -0.0241 -0.0672\n",
       " \n",
       " Columns 153 to 161 \n",
       "    0.0478 -0.0358 -0.0159 -0.0437  0.0814 -0.0375  0.0155 -0.0028  0.0607\n",
       " \n",
       " Columns 162 to 170 \n",
       "   -0.0354 -0.0702  0.0419  0.0175  0.0411 -0.0499 -0.0259 -0.0320  0.0470\n",
       " \n",
       " Columns 171 to 179 \n",
       "    0.0557  0.0112 -0.0030 -0.0060  0.0121  0.0310 -0.0668  0.0362  0.0447\n",
       " \n",
       " Columns 180 to 188 \n",
       "   -0.0289  0.0461 -0.0053 -0.0607  0.0130  0.0788  0.0505  0.0110 -0.0853\n",
       " \n",
       " Columns 189 to 197 \n",
       "   -0.0403 -0.0660 -0.0199  0.0383 -0.0297  0.0246 -0.0318  0.0148 -0.0228\n",
       " \n",
       " Columns 198 to 206 \n",
       "    0.0238  0.0051 -0.0030  0.0040 -0.0110  0.0388  0.0394 -0.0337  0.0022\n",
       " \n",
       " Columns 207 to 215 \n",
       "   -0.0279  0.0033  0.0229  0.0759  0.0010  0.0432  0.0222  0.0448  0.0121\n",
       " \n",
       " Columns 216 to 224 \n",
       "   -0.0610 -0.0396 -0.0034 -0.0101  0.1198 -0.0404 -0.0332  0.0027 -0.0387\n",
       " \n",
       " Columns 225 to 233 \n",
       "   -0.0315  0.0285 -0.0225  0.0561  0.0254 -0.0401 -0.0190 -0.0065 -0.0004\n",
       " \n",
       " Columns 234 to 242 \n",
       "    0.0195  0.1144 -0.0697  0.0327  0.0270  0.0022 -0.0521 -0.0539  0.0143\n",
       " \n",
       " Columns 243 to 251 \n",
       "   -0.0114 -0.0702  0.0754  0.0270  0.0068  0.0191  0.0518 -0.0041  0.0487\n",
       " \n",
       " Columns 252 to 255 \n",
       "    0.0572  0.0388 -0.0171 -0.0457\n",
       " [torch.FloatTensor of size 2x1x256])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ln(test_fuck, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAME_PATH = \"/media/artem/data/Dataset/faces/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 29/33 [08:49<01:13, 18.27s/it]"
     ]
    }
   ],
   "source": [
    "def fixname(s):\n",
    "    return s.split('_')[2]\n",
    "\n",
    "speakers = {}\n",
    "for s in tqdm(os.listdir(FRAME_PATH)):\n",
    "    PATH = path.join(FRAME_PATH, s)\n",
    "    speakers[s] = {}\n",
    "    for folder in os.listdir(PATH):\n",
    "        PATH2 = path.join(PATH, folder)\n",
    "        speakers[s][fixname(folder)] = []\n",
    "        for filename in os.listdir(PATH2):\n",
    "            speakers[s][fixname(folder)].append(imread(path.join(PATH2, filename)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/artem/data/WLAS/gridcorpus/video/align'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5a61c18dc661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWORD_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"align\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mword_alignments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mword_alignments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfixname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mftr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/artem/data/WLAS/gridcorpus/video/align'"
     ]
    }
   ],
   "source": [
    "WORD_PATH = \"/media/artem/data/WLAS/gridcorpus/\"\n",
    "\n",
    "def fixname(s):\n",
    "    return s.split('.')[0]\n",
    "\n",
    "word_alignments = {}\n",
    "for s in tqdm(os.listdir(WORD_PATH)):\n",
    "    PATH = path.join(WORD_PATH, s, \"align\")\n",
    "    word_alignments[s] = {}\n",
    "    for filename in os.listdir(PATH):\n",
    "        word_alignments[s][fixname(filename)] = []\n",
    "        with open(path.join(PATH, filename)) as ftr:\n",
    "            for line in ftr:\n",
    "                l1, l2, w = line.split()\n",
    "                l1 = round(int(l1) / 1000) - 1\n",
    "                l2 = round(int(l2) / 1000) + 1\n",
    "                word_alignments[s][fixname(filename)].append((w, l1, l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sil', -1, 12),\n",
       " ('set', 10, 21),\n",
       " ('blue', 19, 26),\n",
       " ('by', 24, 29),\n",
       " ('u', 27, 33),\n",
       " ('one', 31, 39),\n",
       " ('soon', 37, 49),\n",
       " ('sil', 47, 75)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_alignments['s1']['sbbu1s']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MAX_WORDS = 8\n",
    "MAX_FRAMES = 8\n",
    "for_valida = [\"s5\", \"s14\"]\n",
    "\n",
    "def encode_words(s):\n",
    "    res = []\n",
    "    for word, _, _ in s:\n",
    "        if word == 'sil':\n",
    "            res.append(0)\n",
    "        else:\n",
    "            #print(word, s)\n",
    "            res.extend(ord(a) - ord('a') + 1 for a in word)\n",
    "            res.append(0)\n",
    "    if s[-1][0] != 'sil':\n",
    "        res.pop()\n",
    "    return res\n",
    "\n",
    "def generate_XY(speakers, word_alignments, words_lengths=(1, 2), frame_length=24, drop_rate=0.8):\n",
    "    X, Y = [], []\n",
    "    for s in speakers.keys():\n",
    "        if s in for_valida:\n",
    "            continue\n",
    "        for vid in speakers[s].keys():\n",
    "            if len(speakers[s][vid]) == 75 and vid in word_alignments[s] and np.random.rand() > drop_rate:\n",
    "                length = np.random.choice(np.arange(*words_lengths)) \n",
    "                pos = np.random.choice(len(word_alignments[s][vid]) - length + 1)\n",
    "                l, r = word_alignments[s][vid][pos][1], word_alignments[s][vid][pos + length - 1][2]\n",
    "                l = max(0, l)\n",
    "                if (r - l > frame_length):\n",
    "                    continue\n",
    "                X.append(speakers[s][vid][l:r])\n",
    "                Y.append(encode_words(word_alignments[s][vid][pos:pos+length]))\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, Y = generate_XY(speakers, word_alignments, drop_rate=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_zeros(X):\n",
    "    max_len = max(len(x) for x in X)\n",
    "    return np.array([x + [np.zeros((120, 120)) for i in range(max_len - len(x))] for x in X])\n",
    "\n",
    "def iterate_batch(X, Y, batch_size=32):\n",
    "    ind = np.arange(len(X))\n",
    "    np.random.shuffle(ind)\n",
    "    X = [X[i] for i in ind]\n",
    "    Y = [Y[i] for i in ind]\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        yield add_zeros(X[i:i+batch_size]), Y[i:i+batch_size]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
